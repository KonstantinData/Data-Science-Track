{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zKlvxgawym7g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option(\"display.max_columns\", 300)\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# utility\n",
        "from pprint import pprint\n",
        "import time\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiOhwQb7yqro"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UnIe59-7JEH6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7043, 21)\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "customerID",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "gender",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "SeniorCitizen",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Partner",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Dependents",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "tenure",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "PhoneService",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "MultipleLines",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "InternetService",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "OnlineSecurity",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "OnlineBackup",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "DeviceProtection",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "TechSupport",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "StreamingTV",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "StreamingMovies",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Contract",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "PaperlessBilling",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "PaymentMethod",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "MonthlyCharges",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "TotalCharges",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Churn",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "a5a4c335-015b-4991-8eb5-26db3f27c96d",
              "rows": [
                [
                  "0",
                  "7590-VHVEG",
                  "Female",
                  "0",
                  "Yes",
                  "No",
                  "1",
                  "No",
                  "No phone service",
                  "DSL",
                  "No",
                  "Yes",
                  "No",
                  "No",
                  "No",
                  "No",
                  "Month-to-month",
                  "Yes",
                  "Electronic check",
                  "29.85",
                  "29.85",
                  "No"
                ],
                [
                  "1",
                  "5575-GNVDE",
                  "Male",
                  "0",
                  "No",
                  "No",
                  "34",
                  "Yes",
                  "No",
                  "DSL",
                  "Yes",
                  "No",
                  "Yes",
                  "No",
                  "No",
                  "No",
                  "One year",
                  "No",
                  "Mailed check",
                  "56.95",
                  "1889.5",
                  "No"
                ],
                [
                  "2",
                  "3668-QPYBK",
                  "Male",
                  "0",
                  "No",
                  "No",
                  "2",
                  "Yes",
                  "No",
                  "DSL",
                  "Yes",
                  "Yes",
                  "No",
                  "No",
                  "No",
                  "No",
                  "Month-to-month",
                  "Yes",
                  "Mailed check",
                  "53.85",
                  "108.15",
                  "Yes"
                ],
                [
                  "3",
                  "7795-CFOCW",
                  "Male",
                  "0",
                  "No",
                  "No",
                  "45",
                  "No",
                  "No phone service",
                  "DSL",
                  "Yes",
                  "No",
                  "Yes",
                  "Yes",
                  "No",
                  "No",
                  "One year",
                  "No",
                  "Bank transfer (automatic)",
                  "42.3",
                  "1840.75",
                  "No"
                ],
                [
                  "4",
                  "9237-HQITU",
                  "Female",
                  "0",
                  "No",
                  "No",
                  "2",
                  "Yes",
                  "No",
                  "Fiber optic",
                  "No",
                  "No",
                  "No",
                  "No",
                  "No",
                  "No",
                  "Month-to-month",
                  "Yes",
                  "Electronic check",
                  "70.7",
                  "151.65",
                  "Yes"
                ]
              ],
              "shape": {
                "columns": 21,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>OnlineBackup</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
              "3  7795-CFOCW    Male              0      No         No      45           No   \n",
              "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
              "0  No phone service             DSL             No          Yes   \n",
              "1                No             DSL            Yes           No   \n",
              "2                No             DSL            Yes          Yes   \n",
              "3  No phone service             DSL            Yes           No   \n",
              "4                No     Fiber optic             No           No   \n",
              "\n",
              "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
              "0               No          No          No              No  Month-to-month   \n",
              "1              Yes          No          No              No        One year   \n",
              "2               No          No          No              No  Month-to-month   \n",
              "3              Yes         Yes          No              No        One year   \n",
              "4               No          No          No              No  Month-to-month   \n",
              "\n",
              "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
              "0              Yes           Electronic check           29.85        29.85   \n",
              "1               No               Mailed check           56.95       1889.5   \n",
              "2              Yes               Mailed check           53.85       108.15   \n",
              "3               No  Bank transfer (automatic)           42.30      1840.75   \n",
              "4              Yes           Electronic check           70.70       151.65   \n",
              "\n",
              "  Churn  \n",
              "0    No  \n",
              "1    No  \n",
              "2   Yes  \n",
              "3    No  \n",
              "4   Yes  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(r\"D:\\Git-GitHub\\Repositories\\data-science-track\\data-science-track\\03-machine-learning\\resources\\Telco-Customer-Churn.csv\")\n",
        "print(data.shape)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH9t-2tDx82F"
      },
      "source": [
        "# Check for missing values and duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "KUIk_EFrx6W1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "customerID          0\n",
              "gender              0\n",
              "SeniorCitizen       0\n",
              "Partner             0\n",
              "Dependents          0\n",
              "tenure              0\n",
              "PhoneService        0\n",
              "MultipleLines       0\n",
              "InternetService     0\n",
              "OnlineSecurity      0\n",
              "OnlineBackup        0\n",
              "DeviceProtection    0\n",
              "TechSupport         0\n",
              "StreamingTV         0\n",
              "StreamingMovies     0\n",
              "Contract            0\n",
              "PaperlessBilling    0\n",
              "PaymentMethod       0\n",
              "MonthlyCharges      0\n",
              "TotalCharges        0\n",
              "Churn               0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F1-_ayGryDvh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7043, 21)\n"
          ]
        }
      ],
      "source": [
        "print(data.drop_duplicates().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcJIEweyyJio"
      },
      "source": [
        "There is no duplicate and no missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3xwxO3Pxz-q"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYgwpIpzyNcv"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.12, stratify=data['Churn'], random_state=19)\n",
        "\n",
        "print('train shape: ', train.shape)\n",
        "print('test shape: ', test.shape)\n",
        "\n",
        "train.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5jpCgIjxxus"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KbOL_Ghc6zcU"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO7eVG7EytV8"
      },
      "outputs": [],
      "source": [
        "train['SeniorCitizen'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMakRkcwyzdP"
      },
      "source": [
        "As you can see, \"SeniorCitizen\" is indeed a categorical feature, even though it initially appeared in description!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i6ouuPltRlF"
      },
      "outputs": [],
      "source": [
        "train['Churn'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-MqRw601I4J"
      },
      "source": [
        "It is always good to check the distribution of different levels in your target variable. Data is more or less imbalanced! But nothing terrible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR5dBpp5xHfE"
      },
      "outputs": [],
      "source": [
        "data['customerID'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqZq2ilO1O2p"
      },
      "source": [
        "I could not find anything useful in this feature. It is only an ID. I also investigated both number and letter parts of it. I could not find any pattern in it. So as an ID, it does not provide any information, and we will ignore this feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZCcz1VU1Gzf"
      },
      "outputs": [],
      "source": [
        "num_features = ['tenure', 'MonthlyCharges']\n",
        "cat_features = [el for el in train.columns if el not in ['Churn', 'customerID'] + num_features ]\n",
        "\n",
        "print('num of cat features: ', len(cat_features))\n",
        "pprint(cat_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmiAHP_630Oc"
      },
      "outputs": [],
      "source": [
        "for col in cat_features:\n",
        "  print(col, ': ', train[col].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zatVLGuynxSw"
      },
      "source": [
        "We have one odd categorical feature! \"TotalCharges\"!\n",
        "\n",
        "**Question:** Is it really categorical?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gNKsq2NROE1"
      },
      "outputs": [],
      "source": [
        "train['TotalCharges']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC7XYW474FGF"
      },
      "outputs": [],
      "source": [
        "train['TotalCharges'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdjN_X_14L0X"
      },
      "outputs": [],
      "source": [
        "#train['TotalCharges'].astype(float)\n",
        "# This line fails. It means we have missing values in a special form \" \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH-_WifS40pm"
      },
      "outputs": [],
      "source": [
        "train.loc[train['TotalCharges']==' ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi_nmvFB4b8f"
      },
      "outputs": [],
      "source": [
        "test.loc[test['TotalCharges']==' ']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JOXH8f7oEnC"
      },
      "source": [
        "**Explanation**\n",
        "\n",
        "Because of missing values in a special format \" \", the column has been cast as an object. In Pandas, if a column has a mixture of strings and floats, its type becomes object and therefore it does not appear in train.describe() function!\n",
        "\n",
        "Otherwise, the column is in essence numerical! We have to consider it as such and impute missing values!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYGg9sZKoOx1"
      },
      "outputs": [],
      "source": [
        "train['TotalCharges'].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SChs5WJu49YL"
      },
      "source": [
        "For the moment, let us impute the missing values because we want to perform EDA. Later on, we'll do the imputation in a pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewPesvm55L0z"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.12, stratify=data['Churn'], random_state=19)\n",
        "\n",
        "# Find the indices where train and test having values in TotalCharges\n",
        "missing_indices_train = train.loc[train['TotalCharges']==' '].index\n",
        "missing_indices_test = test.loc[test['TotalCharges']==' '].index\n",
        "\n",
        "median_value = train.loc[~train.index.isin(missing_indices_train), 'TotalCharges'].astype(float).median()\n",
        "train.loc[missing_indices_train, 'TotalCharges'] = median_value\n",
        "test.loc[missing_indices_test, 'TotalCharges'] = median_value  # Use the same median from train for test\n",
        "\n",
        "# After all, we cast the type to float\n",
        "train['TotalCharges'] = train['TotalCharges'].astype(float)\n",
        "test['TotalCharges'] = test['TotalCharges'].astype(float)\n",
        "\n",
        "\n",
        "num_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "cat_features = [el for el in train.columns if el not in ['Churn', 'customerID'] + num_features ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm2X3Z0y2jvn"
      },
      "source": [
        "## Univariate EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3McTYCwF1Gwu"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axs = axs.flatten()\n",
        "\n",
        "# Plot histograms for each column\n",
        "for i, col in enumerate(num_features):\n",
        "    axs[i].hist(train[col], bins=20, edgecolor='black')\n",
        "    axs[i].set_xlabel(col)\n",
        "    axs[i].set_ylabel('Counts')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzEBGlwf5cRl"
      },
      "source": [
        "**Observation**\n",
        "\n",
        "1. All numerical values seem to have a typical distribution with respect to what they represent. Nothing odd to be observed, suc as outliers!\n",
        "\n",
        "\n",
        "Next, let us see some stats on our categorical features as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw-_1lrL56Yq"
      },
      "outputs": [],
      "source": [
        "print(len(cat_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3JabdX62vp3"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(4, 4, figsize=(10, 15))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, col in enumerate(cat_features):\n",
        "  train[col].value_counts(ascending=True).plot(kind='bar', color='blue', ax=axs[i])\n",
        "  axs[i].set\n",
        "\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(i + 1, len(axs)):\n",
        "    fig.delaxes(axs[j])\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBia8oZU8MvZ"
      },
      "source": [
        "## Bivariate EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zm4Ayd0Ut7D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7i2ttFq3kQa"
      },
      "outputs": [],
      "source": [
        "output_dic = {'Yes': 1, 'No': 0}\n",
        "train['Churn_encoded'] = train['Churn'].map(output_dic)\n",
        "train['Churn_encoded'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6cAC9Mh8arZ"
      },
      "outputs": [],
      "source": [
        "def plotCorrelationMatrix(df, figsize=(5, 5)):\n",
        "\n",
        "    # Compute the correlation matrix\n",
        "    corr = df.corr()\n",
        "\n",
        "    # Set up the matplotlib figure\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Generate a heatmap\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
        "\n",
        "    # Set title and adjust layout\n",
        "    plt.title('Correlation Matrix')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4xucKOJV9g_"
      },
      "outputs": [],
      "source": [
        "plotCorrelationMatrix(train[num_features+['Churn_encoded']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o5tk2qEWMs0"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "There is a pretty substantial relationship between the target and three other numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUvsNYxFW1IK"
      },
      "outputs": [],
      "source": [
        "cat_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsc4vKzxXG-n"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(train, test, columns):\n",
        "  for col in columns:\n",
        "    enc = OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse_output=False)\n",
        "    train_encoded = enc.fit_transform(train[[col]])\n",
        "    features = [col + '_' + str(el) for el in enc.categories_[0]]\n",
        "    if train_encoded.shape[1] == 1:\n",
        "      features = [features[1]] # In case it was binary, only consider what is necessary\n",
        "    test_encoded = enc.transform(test[[col]])\n",
        "\n",
        "    train.drop(columns=[col], inplace=True)\n",
        "    train[features] = train_encoded\n",
        "\n",
        "\n",
        "    test.drop(columns=[col], inplace=True)\n",
        "    test[features] = test_encoded\n",
        "\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAZu7vRxeqzn"
      },
      "outputs": [],
      "source": [
        "train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq8qSlmAcF-W"
      },
      "outputs": [],
      "source": [
        "train_encoded, test_encoded = one_hot_encode(train.copy(), test.copy(), cat_features)\n",
        "print(train_encoded.shape)\n",
        "print(test_encoded.shape)\n",
        "\n",
        "train_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFYlaNpgfuxL"
      },
      "outputs": [],
      "source": [
        "ohe_features = [el for el in train_encoded.columns if el not in train.columns]\n",
        "print(len(ohe_features))\n",
        "pprint(ohe_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUgRtlL9f_xX"
      },
      "outputs": [],
      "source": [
        "plotCorrelationMatrix(train_encoded[ohe_features+['Churn_encoded']], figsize=(25, 25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoTw68v0gtM6"
      },
      "source": [
        "**Observations**\n",
        "\n",
        "1. The feature \"Contract_Month-to-month\" has the strongest positive correlation with churn=\"yes\". What does this mean? It means, if the contract is month to month, there is a high likelihood that the customer might want to cancel it soon. It makes sense!\n",
        "\n",
        "2. After that, other important features are \"TechSuppot_No\" and \"OnlineSecurity_No\"\n",
        "\n",
        "3. Some features in the middle, have almost 100% and in one case, -100% correlationship with each other! It means, we can perhaps drop some of those features because the other ones replace them effectively!\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpBmAZXDhi67"
      },
      "source": [
        "For the moment, we first train a baseline model just as it is without any feature selection or engineering!\n",
        "\n",
        "# Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX-EltAcYoFz"
      },
      "outputs": [],
      "source": [
        "# It is better to repeat every operation we performed on train and test so far, just in case we might have done a mistake.\n",
        "# This makes sure our data is what we expect it to be\n",
        "\n",
        "def preprocess_data_LR(data, log_transform=True):\n",
        "  train, test = train_test_split(data, test_size=0.12, stratify=data['Churn'], random_state=19)\n",
        "\n",
        "  # Taking care of missing values\n",
        "  missing_indices_train = train.loc[train['TotalCharges']==' '].index\n",
        "  missing_indices_test = test.loc[test['TotalCharges']==' '].index\n",
        "  median_value = train.loc[~train.index.isin(missing_indices_train), 'TotalCharges'].astype(float).median()\n",
        "  train.loc[missing_indices_train, 'TotalCharges'] = median_value\n",
        "  test.loc[missing_indices_test, 'TotalCharges'] = median_value  # Use the same median from train for test\n",
        "  # After all, we cast the type to float\n",
        "  train['TotalCharges'] = train['TotalCharges'].astype(float)\n",
        "  test['TotalCharges'] = test['TotalCharges'].astype(float)\n",
        "\n",
        "  # map the outputs as well\n",
        "  output_dic = {'Yes': 1, 'No': 0}\n",
        "  train['Churn'] = train['Churn'].map(output_dic)\n",
        "  test['Churn'] = test['Churn'].map(output_dic)\n",
        "\n",
        "  # get numerical and categorical features\n",
        "  num_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "  cat_features = [el for el in train.columns if el not in ['Churn', 'customerID'] + num_features ]\n",
        "\n",
        "  # Perform scaling on numerical features for Logistic Regression\n",
        "  if log_transform:\n",
        "    for col in num_features:\n",
        "      train[col] = np.log1p(train[col])\n",
        "      test[col] = np.log1p(test[col])\n",
        "\n",
        "  # one hot encode categorical features\n",
        "  train_encoded, test_encoded = one_hot_encode(train.copy(), test.copy(), cat_features)\n",
        "\n",
        "  ohe_features = [el for el in train_encoded.columns if el not in train.columns]\n",
        "\n",
        "  return train_encoded, test_encoded, num_features, ohe_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9FqJHBoWM7C"
      },
      "outputs": [],
      "source": [
        "def get_model_inputs(train_encoded, test_encoded, num_features, ohe_features):\n",
        "  X_train = train_encoded[num_features + ohe_features].values\n",
        "  y_train = train_encoded['Churn'].values\n",
        "  X_test = test_encoded[num_features + ohe_features].values\n",
        "  y_test = test_encoded['Churn'].values\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLBjGhWwWRbu"
      },
      "outputs": [],
      "source": [
        "train_encoded, test_encoded, num_features, ohe_features = preprocess_data_LR(data, log_transform=True)\n",
        "X_train, y_train, X_test, y_test = get_model_inputs(train_encoded, test_encoded, num_features, ohe_features)\n",
        "\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2YnLNhLFFnf"
      },
      "outputs": [],
      "source": [
        "train_encoded.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T1l_T0igJYB"
      },
      "outputs": [],
      "source": [
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "logistic_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbQRp6Icbx_u"
      },
      "outputs": [],
      "source": [
        "# Define the evaluation function\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    # Train predictions\n",
        "    train_pred = model.predict(X_train)\n",
        "\n",
        "    # Test predictions\n",
        "    test_pred = model.predict(X_test)\n",
        "\n",
        "    # Train accuracy\n",
        "    train_accuracy = accuracy_score(y_train, train_pred)\n",
        "    print(\"Train Accuracy:\", train_accuracy)\n",
        "\n",
        "    # Test accuracy\n",
        "    test_accuracy = accuracy_score(y_test, test_pred)\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "    # Train confusion matrix\n",
        "    train_conf_matrix = confusion_matrix(y_train, train_pred)\n",
        "    print(\"\\nTrain Confusion Matrix:\")\n",
        "    print(train_conf_matrix)\n",
        "\n",
        "    # Test confusion matrix\n",
        "    test_conf_matrix = confusion_matrix(y_test, test_pred)\n",
        "    print(\"\\nTest Confusion Matrix:\")\n",
        "    print(test_conf_matrix)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score for training set\n",
        "    train_precision = precision_score(y_train, train_pred)\n",
        "    train_recall = recall_score(y_train, train_pred)\n",
        "    train_f1_score = f1_score(y_train, train_pred)\n",
        "\n",
        "    print(\"\\nTrain Precision:\", train_precision)\n",
        "    print(\"Train Recall:\", train_recall)\n",
        "    print(\"Train F1 Score:\", train_f1_score)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score for test set\n",
        "    test_precision = precision_score(y_test, test_pred)\n",
        "    test_recall = recall_score(y_test, test_pred)\n",
        "    test_f1_score = f1_score(y_test, test_pred)\n",
        "\n",
        "    print(\"\\nTest Precision:\", test_precision)\n",
        "    print(\"Test Recall:\", test_recall)\n",
        "    print(\"Test F1 Score:\", test_f1_score)\n",
        "\n",
        "    # Train ROC AUC score\n",
        "    train_roc_auc = roc_auc_score(y_train, train_pred)\n",
        "    print(\"\\nTrain ROC AUC Score:\", train_roc_auc)\n",
        "\n",
        "    # Test ROC AUC score\n",
        "    test_roc_auc = roc_auc_score(y_test, test_pred)\n",
        "    print(\"Test ROC AUC Score:\", test_roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf1iP4kRcIIx"
      },
      "outputs": [],
      "source": [
        "evaluate_model(logistic_model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS2OFQx5cSZS"
      },
      "outputs": [],
      "source": [
        "# If we remember we had\n",
        "train['Churn'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkW8kcQscpO5"
      },
      "source": [
        "It means, if we predict everything as No, we already get an accuracy of 73%. This is called the null classifier.\n",
        "\n",
        "Our logistic Regression achieved an accuracy of 81.8% with log transformation. That is already better than the null classifier! One step to the positive direction. Also, if we don't perform log transformation, the accuracy is 81.4%!\n",
        "\n",
        "Log transformation is awesome for numerical features!\n",
        "\n",
        "Can we do better?\n",
        "\n",
        "Although Logistic regression has some hyperparameters, and we can obviously tune them, it is not worth the effort because there are better models. We save the efforts for them.\n",
        "\n",
        "But at least we have a baseline.\n",
        "\n",
        "Can we do better before we try another model? Perhaps let us do some feature selection!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbLXJxr9KIQg"
      },
      "outputs": [],
      "source": [
        "ohe_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5G9x5R7KEnC"
      },
      "outputs": [],
      "source": [
        "# We will drop the following features\n",
        "\n",
        "features_to_drop = [ # drop because of 100% correlations\n",
        "                    'MultipleLines_No phone service',  # for -100% correlation\n",
        "                    'InternetService_No',\n",
        "                    'OnlineSecurity_No internet service',\n",
        "                    'OnlineBackup_No internet service',\n",
        "                    'DeviceProtection_No internet service',\n",
        "                    'TechSupport_No internet service',\n",
        "                    'StreamingMovies_No internet service',\n",
        "\n",
        "                    # Drop because correlation is 1%\n",
        "                    'gender_Male',\n",
        "                    'PhoneService_Yes'\n",
        "                    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYxq-D7wL6ar"
      },
      "outputs": [],
      "source": [
        "train_encoded.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbhfkO23Lte4"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test = get_model_inputs(train_encoded.drop(columns=features_to_drop),\n",
        "                                                    test_encoded.drop(columns=features_to_drop),\n",
        "                                                    num_features,\n",
        "                                                    [el for el in ohe_features if el not in features_to_drop])\n",
        "\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUt8s8yDLtcJ"
      },
      "outputs": [],
      "source": [
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "evaluate_model(logistic_model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl-z7neSNsws"
      },
      "source": [
        "We saw that we could further improve test accuracy be deselecting some unimportant features, especially the last two. Could it further improve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaDdwKwdLtae"
      },
      "outputs": [],
      "source": [
        "features_to_drop = [ # drop because of 100% correlations\n",
        "                    'MultipleLines_No phone service',\n",
        "                    'InternetService_No',\n",
        "                    'OnlineSecurity_No internet service',\n",
        "                    'OnlineBackup_No internet service',\n",
        "                    'DeviceProtection_No internet service',\n",
        "                    'TechSupport_No internet service',\n",
        "                    'StreamingMovies_No internet service',\n",
        "\n",
        "                    # Drop because correlation is 1%\n",
        "                    'gender_Male',\n",
        "                    'PhoneService_Yes',\n",
        "\n",
        "                    # drop because correlation is 5%\n",
        "                    'MultipleLines_No',\n",
        "                    'MultipleLines_Yes'\n",
        "                    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaoyftDiLtXg"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test = get_model_inputs(train_encoded.drop(columns=features_to_drop),\n",
        "                                                    test_encoded.drop(columns=features_to_drop),\n",
        "                                                    num_features,\n",
        "                                                    [el for el in ohe_features if el not in features_to_drop])\n",
        "\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH7Uf1V-OcJA"
      },
      "outputs": [],
      "source": [
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "evaluate_model(logistic_model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQmgSc0UOf7h"
      },
      "source": [
        "It was too much. Previous feature selection was the best! The last two features we dropped had some information which we lost!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grOSNsiyeLSC"
      },
      "source": [
        "# KNN\n",
        "\n",
        "Since we have some numerical features, it is better to scale them before applying KNN. We use log transformation. Although one can try StandardScaler and MinMaxScaler as well!\n",
        "\n",
        "Although there are some 9 missing values in the train data, doing a pipeline to prevent data leakage from happening is not worth the effort. Also, log transformation does not lead to data leakage because there is no encoder being fit on train!\n",
        "\n",
        "So we leave out pipeline and proceed with the data we preprocessed for Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o3MOnIB_sv7"
      },
      "outputs": [],
      "source": [
        "train_encoded, test_encoded, num_features, ohe_features = preprocess_data_LR(data)\n",
        "\n",
        "\n",
        "features_to_drop = [ # drop because of 100% correlations\n",
        "                    'MultipleLines_No phone service',\n",
        "                    'InternetService_No',\n",
        "                    'OnlineSecurity_No internet service',\n",
        "                    'OnlineBackup_No internet service',\n",
        "                    'DeviceProtection_No internet service',\n",
        "                    'TechSupport_No internet service',\n",
        "                    'StreamingMovies_No internet service',\n",
        "\n",
        "                    # Drop because correlation is 1%\n",
        "                    'gender_Male',\n",
        "                    'PhoneService_Yes'\n",
        "                    ]\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = get_model_inputs(train_encoded.drop(columns=features_to_drop),\n",
        "                                                    test_encoded.drop(columns=features_to_drop),\n",
        "                                                    num_features,\n",
        "                                                    [el for el in ohe_features if el not in features_to_drop])\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTfAAXJT_WCH"
      },
      "outputs": [],
      "source": [
        "k_values = list(range(1, 71))\n",
        "param_grid = {'n_neighbors': k_values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWsAye1F_4xZ"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "clf = KNeighborsClassifier()\n",
        "grid = GridSearchCV(estimator=clf,\n",
        "                    param_grid=param_grid,\n",
        "                    scoring='accuracy', # 'f1',\n",
        "                    n_jobs=-1,\n",
        "                    cv=10,\n",
        "                    verbose=3\n",
        "                    )\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Time taken: %d seconds.\"%(time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glUu4f9IAzrZ"
      },
      "outputs": [],
      "source": [
        "grid.cv_results_['mean_test_score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya5gyZuABHUW"
      },
      "outputs": [],
      "source": [
        "# Plot mean cross-validation scores vs K\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.plot(k_values, grid.cv_results_['mean_test_score'], marker='o', linestyle='-')\n",
        "plt.title('Mean Cross-Validation Score vs K for KNN')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Mean Cross-Validation Score')\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2g79ePfAQgb"
      },
      "outputs": [],
      "source": [
        "print(grid.best_score_)\n",
        "print(grid.best_params_)\n",
        "best_estimator = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMNOuqBwDGNo"
      },
      "outputs": [],
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=60)\n",
        "knn_model.fit(X_train, y_train)\n",
        "evaluate_model(knn_model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRhTIHC6Yi9x"
      },
      "source": [
        "We see that KNN worked well, but not as good as the best LR we trained!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td2dc5k3De57"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-vC6yuTQSB9"
      },
      "source": [
        "For SVM, we also scale the numerical features like in KNN. Therefore, we can already use X_train, y_train, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKJX9ouEP1fy"
      },
      "outputs": [],
      "source": [
        "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "param_grid = {'kernel': ['linear'],\n",
        "              'C': C_values}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stRQJ5s9DZlZ"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "clf = SVC(kernel='linear')\n",
        "grid = GridSearchCV(estimator=clf,\n",
        "                    param_grid=param_grid,\n",
        "                    scoring='accuracy', # 'f1',\n",
        "                    n_jobs=-1,\n",
        "                    cv=10,\n",
        "                    verbose=3\n",
        "                    )\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Time taken: %d seconds.\"%(time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnjRU7UfQZ8K"
      },
      "outputs": [],
      "source": [
        "# Plot cross-validation scores vs C\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(C_values, grid.cv_results_['mean_test_score'], marker='o', linestyle='-')\n",
        "plt.title('Mean Cross-Validation Score vs C for SVM with Linear Kernel')\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Mean Cross-Validation Score')\n",
        "plt.xscale('log')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIkZcY98WKxQ"
      },
      "source": [
        "\n",
        "\n",
        "> ### High values for C mean more of hard margine, more potentially overfitting.\n",
        "\n",
        "\n",
        "\n",
        "> ### Smaller values for C mean more of soft margin, allowing for more mistakes to happen and less of overfitting!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn1k-qyRVuKW"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "best_svm_model = SVC(kernel='linear', C=0.1)\n",
        "best_svm_model.fit(X_train, y_train)\n",
        "evaluate_model(best_svm_model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYZVvF1bfZcH"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "best_svm_model = SVC(kernel='rbf', C=0.1)\n",
        "best_svm_model.fit(X_train, y_train)\n",
        "evaluate_model(best_svm_model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OLj-ZSHkDsS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWW6HQMAYwll"
      },
      "source": [
        "So far LR has been the ebst model we have achieved!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_E_Sdj9Ytf-"
      },
      "source": [
        "# Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzzcwNAg0vu3"
      },
      "outputs": [],
      "source": [
        "def preprocess_data_DT(data):\n",
        "  train, test = train_test_split(data, test_size=0.12, stratify=data['Churn'], random_state=19)\n",
        "\n",
        "  # Taking care of missing values\n",
        "  missing_indices_train = train.loc[train['TotalCharges']==' '].index\n",
        "  missing_indices_test = test.loc[test['TotalCharges']==' '].index\n",
        "  # We impute it with negative values\n",
        "  train.loc[missing_indices_train, 'TotalCharges'] = -99\n",
        "  test.loc[missing_indices_test, 'TotalCharges'] = -99\n",
        "  # After all, we cast the type to float\n",
        "  train['TotalCharges'] = train['TotalCharges'].astype(float)\n",
        "  test['TotalCharges'] = test['TotalCharges'].astype(float)\n",
        "\n",
        "  # map the outputs as well\n",
        "  output_dic = {'Yes': 1, 'No': 0}\n",
        "  train['Churn'] = train['Churn'].map(output_dic)\n",
        "  test['Churn'] = test['Churn'].map(output_dic)\n",
        "\n",
        "  # get numerical and categorical features\n",
        "  num_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "  cat_features = [el for el in train.columns if el not in ['Churn', 'customerID'] + num_features ]\n",
        "\n",
        "\n",
        "  # one hot encode categorical features\n",
        "  train_encoded, test_encoded = one_hot_encode(train.copy(), test.copy(), cat_features)\n",
        "\n",
        "  ohe_features = [el for el in train_encoded.columns if el not in train.columns]\n",
        "\n",
        "  return train_encoded, test_encoded, num_features, ohe_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl_MWsXt1MK9"
      },
      "outputs": [],
      "source": [
        "train_encoded, test_encoded, num_features, ohe_features = preprocess_data_DT(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t12w_W2EbEx8"
      },
      "outputs": [],
      "source": [
        "train_encoded.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfIZqWEh1n-0"
      },
      "outputs": [],
      "source": [
        "features_to_drop = [ # drop because of 100% correlations\n",
        "                    'MultipleLines_No phone service',\n",
        "                    'InternetService_No',\n",
        "                    'OnlineSecurity_No internet service',\n",
        "                    'OnlineBackup_No internet service',\n",
        "                    'DeviceProtection_No internet service',\n",
        "                    'TechSupport_No internet service',\n",
        "                    'StreamingMovies_No internet service',\n",
        "\n",
        "                    # Drop because correlation is 1%\n",
        "                    #'gender_Male',\n",
        "                    #'PhoneService_Yes'\n",
        "                    ]\n",
        "\n",
        "X_train, y_train, X_test, y_test = get_model_inputs(train_encoded.drop(columns=features_to_drop),\n",
        "                                                    test_encoded.drop(columns=features_to_drop),\n",
        "                                                    num_features,\n",
        "                                                    [el for el in ohe_features if el not in features_to_drop])\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxUCXKgTW_t-"
      },
      "outputs": [],
      "source": [
        "decision_tree = DecisionTreeClassifier(random_state=11)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(decision_tree, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DQ81UFyPclbz"
      },
      "outputs": [],
      "source": [
        "help(DecisionTreeClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTSA-U7XbQYG"
      },
      "outputs": [],
      "source": [
        "decision_tree = DecisionTreeClassifier(max_depth=4,\n",
        "                                       random_state=11)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(decision_tree, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQLPTZfVbjUB"
      },
      "outputs": [],
      "source": [
        "param_grid = {'criterion': ['gini'], # 'entropy', 'log_loss'],\n",
        "              'max_depth': [4, 5, 6, 7, 8, 9, 10, 15],\n",
        "              'min_samples_split': [2, 4, 6],\n",
        "              'min_samples_leaf': [1, 2, 4]\n",
        "              }\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=11)\n",
        "grid = GridSearchCV(estimator=clf,\n",
        "                    param_grid=param_grid,\n",
        "                    scoring='accuracy', # 'f1',\n",
        "                    n_jobs=-1,\n",
        "                    cv=10,\n",
        "                    verbose=3\n",
        "                    )\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Time taken: %d seconds.\"%(time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNNvraWkdl1Z"
      },
      "outputs": [],
      "source": [
        "print(grid.best_score_)\n",
        "print(grid.best_params_)\n",
        "best_estimator = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB-CkWnFeSMu"
      },
      "outputs": [],
      "source": [
        "decision_tree = DecisionTreeClassifier(**grid.best_params_,\n",
        "                                       random_state=11)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(decision_tree, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1YRUiLOeq9a"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "The data we use for random forest is similar to what we use for decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIINSE0qeeks"
      },
      "outputs": [],
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=11)\n",
        "\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(rf_classifier, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-6x1nNSgcRc"
      },
      "source": [
        "Clearly we have some overfitting in Random Forest because train accuracy is very high. Now we need to optimize hyperparameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs6TyKWjgSwd"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 150, 200, 250, 300],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'random_state': [11]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSHFFubphFAX"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "random_search = RandomizedSearchCV(clf,\n",
        "                                   param_grid,\n",
        "                                   n_iter=100,\n",
        "                                   cv=10,\n",
        "                                   verbose=2,\n",
        "                                   random_state=11,\n",
        "                                   n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Time taken: %d seconds.\"%(time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H46MrsJhgdm"
      },
      "outputs": [],
      "source": [
        "print(random_search.best_score_)\n",
        "print(random_search.best_params_)\n",
        "best_estimator = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt6MlSPojiK7"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(**random_search.best_params_)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(rf, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G8gXUBu_ZZn"
      },
      "source": [
        "# AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_kJ9Kso96pI"
      },
      "outputs": [],
      "source": [
        "train_encoded, test_encoded, num_features, ohe_features = preprocess_data_LR(data)\n",
        "\n",
        "\n",
        "features_to_drop = [ # drop because of 100% correlations\n",
        "                    'MultipleLines_No phone service',\n",
        "                    'InternetService_No',\n",
        "                    'OnlineSecurity_No internet service',\n",
        "                    'OnlineBackup_No internet service',\n",
        "                    'DeviceProtection_No internet service',\n",
        "                    'TechSupport_No internet service',\n",
        "                    'StreamingMovies_No internet service',\n",
        "\n",
        "                    # Drop because correlation is 1%\n",
        "                    'gender_Male',\n",
        "                    'PhoneService_Yes'\n",
        "                    ]\n",
        "\n",
        "\n",
        "X_train, y_train, X_test, y_test = get_model_inputs(train_encoded.drop(columns=features_to_drop),\n",
        "                                                    test_encoded.drop(columns=features_to_drop),\n",
        "                                                    num_features,\n",
        "                                                    [el for el in ohe_features if el not in features_to_drop])\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8Im66d8_OQF"
      },
      "outputs": [],
      "source": [
        "base_estimator = DecisionTreeClassifier(max_depth=3)\n",
        "adaboost = AdaBoostClassifier(estimator=base_estimator,\n",
        "                         learning_rate=0.02,\n",
        "                         n_estimators=300,\n",
        "                         random_state=11)\n",
        "\n",
        "adaboost.fit(X_train, y_train)\n",
        "evaluate_model(adaboost, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9eGrHeo_2D1"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [200, 300, 400],\n",
        "    'learning_rate': [0.01, 0.02],\n",
        "    'estimator__max_depth': [3, 4],\n",
        "    'estimator__min_samples_split': [2, 5],\n",
        "    'estimator__min_samples_leaf': [1, 2,]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v9opY_3Au50"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "ada = AdaBoostClassifier(estimator=base_estimator)\n",
        "\n",
        "grid_search = GridSearchCV(ada, param_grid, cv=10, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Time taken: %d seconds.\"%(time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubD0mzEMJ3vQ"
      },
      "outputs": [],
      "source": [
        "print(grid_search.best_score_)\n",
        "best_estimator = grid_search.best_estimator_\n",
        "print(best_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKjMyoPKA7YN"
      },
      "outputs": [],
      "source": [
        "best_estimator.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(best_estimator, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRePXr8KJoH8"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [300, 350, 400],\n",
        "    'learning_rate': [0.01, 0.02, 0.3, 0.4, 0.5],\n",
        "    'estimator__max_depth': [3],\n",
        "    'estimator__min_samples_split': [4, 5],\n",
        "    'estimator__min_samples_leaf': [2, 3]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6-fVxs-pedD"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "ada = AdaBoostClassifier(estimator=base_estimator)\n",
        "\n",
        "grid_search = GridSearchCV(ada, param_grid, cv=10, verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Time taken: %d seconds.\"%(time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTy-Ty55pjGi"
      },
      "outputs": [],
      "source": [
        "print(grid_search.best_score_)\n",
        "best_estimator = grid_search.best_estimator_\n",
        "print(best_estimator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYABzdc5plic"
      },
      "outputs": [],
      "source": [
        "best_estimator.fit(X_train, y_train)\n",
        "\n",
        "evaluate_model(best_estimator, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSMlwgzjpnco"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
